{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 'the cat', probabilities:\n",
      "sat: 0.20\n",
      "jumped: 0.20\n",
      "but: 0.20\n",
      "was: 0.20\n",
      "looked: 0.20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class NgramModel:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.ngrams = defaultdict(Counter)\n",
    "        self.vocab = set()\n",
    "\n",
    "    def train(self, text):\n",
    "        # Convert text to list of tokens\n",
    "        tokens = text.lower().split()\n",
    "        self.vocab.update(tokens)\n",
    "        \n",
    "        # Create n-grams\n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            context = tuple(tokens[i:i+self.n-1])\n",
    "            target = tokens[i+self.n-1]\n",
    "            self.ngrams[context][target] += 1\n",
    "\n",
    "    def predict_next(self, context):\n",
    "        context = tuple(context.lower().split()[-self.n+1:])\n",
    "        if context in self.ngrams:\n",
    "            candidates = self.ngrams[context]\n",
    "            total = sum(candidates.values())\n",
    "            return {word: count/total for word, count in candidates.items()}\n",
    "        return {}\n",
    "\n",
    "# Example usage with longer text\n",
    "text = \"the cat sat on the mat while the dog sat on the floor the cat jumped over the fence and the dog chased after the cat but the cat was too quick and climbed up the tree while the dog barked at the bottom of the tree the cat looked down at the dog with amusement\"\n",
    "model = NgramModel(3)  # trigram model\n",
    "model.train(text)\n",
    "\n",
    "# Predict next word\n",
    "context = \"the cat\"\n",
    "probabilities = model.predict_next(context)\n",
    "print(f\"After '{context}', probabilities:\")\n",
    "for word, prob in probabilities.items():\n",
    "    print(f\"{word}: {prob:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'the cat': 0.053333\n",
      "Probability of 'the dog': 0.026667\n",
      "Probability of 'the cat sat': 0.004354\n",
      "Probability of 'the dog barked': 0.000000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class BigramModel:\n",
    "    def __init__(self):\n",
    "        self.bigrams = defaultdict(Counter)\n",
    "        self.vocab = set()\n",
    "\n",
    "    def train(self, text):\n",
    "        # Convert text to list of tokens\n",
    "        tokens = text.lower().split()\n",
    "        self.vocab.update(tokens)\n",
    "        \n",
    "        # Create bigrams\n",
    "        for i in range(len(tokens) - 1):\n",
    "            context = tokens[i]\n",
    "            target = tokens[i + 1]\n",
    "            self.bigrams[context][target] += 1\n",
    "\n",
    "    def predict_next(self, context):\n",
    "        if context in self.bigrams:\n",
    "            candidates = self.bigrams[context]\n",
    "            total = sum(candidates.values())\n",
    "            return {word: count / total for word, count in candidates.items()}\n",
    "        return {}\n",
    "\n",
    "    def sentence_probability(self, sentence):\n",
    "        tokens = sentence.lower().split()\n",
    "        prob = 1.0\n",
    "        for i in range(len(tokens) - 1):\n",
    "            context = tokens[i]\n",
    "            target = tokens[i + 1]\n",
    "            if context in self.bigrams and target in self.bigrams[context]:\n",
    "                prob *= self.bigrams[context][target] / sum(self.bigrams[context].values())\n",
    "            else:\n",
    "                prob *= 0.0\n",
    "        return prob\n",
    "\n",
    "# Generate training data (1000 words)\n",
    "words = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"while\", \"dog\", \"jumped\", \"over\", \"fence\", \"chased\", \"after\", \"quick\", \"climbed\", \"up\", \"tree\", \"barked\", \"at\", \"bottom\", \"looked\", \"down\", \"with\", \"amusement\"]\n",
    "training_text = \" \".join(random.choices(words, k=1000))\n",
    "\n",
    "# Train the bigram model\n",
    "bigram_model = BigramModel()\n",
    "bigram_model.train(training_text)\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\"the cat\", \"the dog\", \"the cat sat\", \"the dog barked\"]\n",
    "\n",
    "# Estimate probabilities for test sentences\n",
    "for sentence in test_sentences:\n",
    "    prob = bigram_model.sentence_probability(sentence)\n",
    "    print(f\"Probability of '{sentence}': {prob:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
