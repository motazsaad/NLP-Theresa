{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-30T06:05:46.036808Z","iopub.execute_input":"2024-10-30T06:05:46.037117Z","iopub.status.idle":"2024-10-30T06:05:47.223545Z","shell.execute_reply.started":"2024-10-30T06:05:46.037067Z","shell.execute_reply":"2024-10-30T06:05:47.222619Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Install Required Libraries\n","metadata":{}},{"cell_type":"code","source":"pip install transformers datasets -q ","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:06:00.373499Z","iopub.execute_input":"2024-10-30T06:06:00.374013Z","iopub.status.idle":"2024-10-30T06:06:13.238927Z","shell.execute_reply.started":"2024-10-30T06:06:00.373975Z","shell.execute_reply":"2024-10-30T06:06:13.237795Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:06:24.230486Z","iopub.execute_input":"2024-10-30T06:06:24.231079Z","iopub.status.idle":"2024-10-30T06:06:45.324815Z","shell.execute_reply.started":"2024-10-30T06:06:24.231030Z","shell.execute_reply":"2024-10-30T06:06:45.323860Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Load the Dataset\n\nSummarization data from Hugging face ","metadata":{}},{"cell_type":"code","source":"# Load a sample dataset\ndataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:1%]\")\n\n# Preprocess function\ndef preprocess_data(examples):\n    # Add the task prefix if needed (like for summarization)\n    inputs = [\"summarize: \" + doc for doc in examples[\"article\"]]\n    \n    # Tokenize the inputs with padding and truncation\n    model_inputs = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True)\n    \n    # Tokenize the labels (e.g., summaries) with padding and truncation\n    labels = tokenizer(examples[\"highlights\"], max_length=128, padding=\"max_length\", truncation=True).input_ids\n    \n    # Replace label pad tokens with -100 to ignore them in loss calculation\n    labels = [[(label if label != tokenizer.pad_token_id else -100) for label in label_ids] for label_ids in labels]\n    \n    model_inputs[\"labels\"] = labels\n    return model_inputs\n\n\n# Initialize tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n# Apply preprocessing\ndataset = dataset.map(preprocess_data, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:13:43.121344Z","iopub.execute_input":"2024-10-30T06:13:43.121819Z","iopub.status.idle":"2024-10-30T06:14:02.722352Z","shell.execute_reply.started":"2024-10-30T06:13:43.121779Z","shell.execute_reply":"2024-10-30T06:14:02.721254Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2871 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bf70cc580da43a49883519cdb1cb7bb"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Display a Dataset Sample","metadata":{}},{"cell_type":"code","source":"# Load a sample dataset (if not already loaded)\nfrom datasets import load_dataset\n\n# Example: loading the CNN/DailyMail dataset\ndataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:1%]\")\n\n# Display a sample of 5 rows\ndataset_sample = dataset.select(range(5))  # Select the first 5 samples\n\n# Convert to a pandas DataFrame for easy viewing (optional)\ndataset_sample_df = dataset_sample.to_pandas()\n\n# Show the sample\ndataset_sample_df\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:22:03.987290Z","iopub.execute_input":"2024-10-30T06:22:03.988173Z","iopub.status.idle":"2024-10-30T06:22:05.936454Z","shell.execute_reply.started":"2024-10-30T06:22:03.988130Z","shell.execute_reply":"2024-10-30T06:22:05.935448Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                             article  \\\n0  LONDON, England (Reuters) -- Harry Potter star...   \n1  Editor's note: In our Behind the Scenes series...   \n2  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n3  WASHINGTON (CNN) -- Doctors removed five small...   \n4  (CNN)  -- The National Football League has ind...   \n\n                                          highlights  \\\n0  Harry Potter star Daniel Radcliffe gets £20M f...   \n1  Mentally ill inmates in Miami are housed on th...   \n2  NEW: \"I thought I was going to die,\" driver sa...   \n3  Five small polyps found during procedure; \"non...   \n4  NEW: NFL chief, Atlanta Falcons owner critical...   \n\n                                         id  \n0  42c027e4ff9730fbb3de84c1af0d2c506e41c3e4  \n1  ee8871b15c50d0db17b0179a6d2beab35065f1e9  \n2  06352019a19ae31e527f37f7571c6dd7f0c5da37  \n3  24521a2abb2e1f5e34e6824e0f9e56904a2b0e88  \n4  7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article</th>\n      <th>highlights</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n      <td>Harry Potter star Daniel Radcliffe gets £20M f...</td>\n      <td>42c027e4ff9730fbb3de84c1af0d2c506e41c3e4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Editor's note: In our Behind the Scenes series...</td>\n      <td>Mentally ill inmates in Miami are housed on th...</td>\n      <td>ee8871b15c50d0db17b0179a6d2beab35065f1e9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...</td>\n      <td>NEW: \"I thought I was going to die,\" driver sa...</td>\n      <td>06352019a19ae31e527f37f7571c6dd7f0c5da37</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n      <td>Five small polyps found during procedure; \"non...</td>\n      <td>24521a2abb2e1f5e34e6824e0f9e56904a2b0e88</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(CNN)  -- The National Football League has ind...</td>\n      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n      <td>7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Initialize the Model\n\nYou can Choose a T5 model variant based on your compute resources, like t5-small, t5-base, or t5-large.","metadata":{}},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:15:19.480456Z","iopub.execute_input":"2024-10-30T06:15:19.481532Z","iopub.status.idle":"2024-10-30T06:15:19.983847Z","shell.execute_reply.started":"2024-10-30T06:15:19.481479Z","shell.execute_reply":"2024-10-30T06:15:19.982868Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Define Training Arguments\n\nSet up the hyperparameters for training. Adjust values like learning_rate, num_train_epochs, and per_device_train_batch_size as needed.","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=3e-4,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    report_to='none'\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:16:48.285442Z","iopub.execute_input":"2024-10-30T06:16:48.286339Z","iopub.status.idle":"2024-10-30T06:16:48.318399Z","shell.execute_reply.started":"2024-10-30T06:16:48.286299Z","shell.execute_reply":"2024-10-30T06:16:48.317651Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Create the Trainer\n\nThe Trainer class manages the training loop, making it easy to handle the model, arguments, dataset, and other element","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset,\n    eval_dataset=dataset,  # Use a separate eval dataset in practice\n    tokenizer=tokenizer,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:16:52.751095Z","iopub.execute_input":"2024-10-30T06:16:52.751885Z","iopub.status.idle":"2024-10-30T06:16:52.871761Z","shell.execute_reply.started":"2024-10-30T06:16:52.751842Z","shell.execute_reply":"2024-10-30T06:16:52.870877Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model\nFine-tune the model using the dataset and arguments defined above.","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:04:05.224123Z","iopub.execute_input":"2024-10-30T07:04:05.224597Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='711' max='1077' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 711/1077 03:07 < 01:36, 3.79 it/s, Epoch 1.98/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.846100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluate the Model","metadata":{}},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:31:25.667126Z","iopub.execute_input":"2024-10-30T06:31:25.667529Z","iopub.status.idle":"2024-10-30T06:32:02.286057Z","shell.execute_reply.started":"2024-10-30T06:31:25.667488Z","shell.execute_reply":"2024-10-30T06:32:02.285138Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='359' max='359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [359/359 00:36]\n    </div>\n    "},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.5671461820602417,\n 'eval_runtime': 36.6089,\n 'eval_samples_per_second': 78.424,\n 'eval_steps_per_second': 9.806,\n 'epoch': 3.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Save the Model","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"./fine-tuned-t5\")\ntokenizer.save_pretrained(\"./fine-tuned-t5\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:32:14.081250Z","iopub.execute_input":"2024-10-30T06:32:14.082033Z","iopub.status.idle":"2024-10-30T06:32:14.606116Z","shell.execute_reply.started":"2024-10-30T06:32:14.081981Z","shell.execute_reply":"2024-10-30T06:32:14.605184Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"('./fine-tuned-t5/tokenizer_config.json',\n './fine-tuned-t5/special_tokens_map.json',\n './fine-tuned-t5/spiece.model',\n './fine-tuned-t5/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"# Generate Predictions","metadata":{}},{"cell_type":"code","source":"# Check if a GPU is available and set the device accordingly\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Move the model to the appropriate device\nmodel.to(device)\n\n# Sample text to summarize\ntext = \"\"\"\nArtificial intelligence (AI) has revolutionized various industries by automating complex tasks and analyzing vast amounts of data with precision. From healthcare to finance, AI-driven solutions provide valuable insights and streamline processes. \nFor instance, in healthcare, AI aids in early disease detection through image analysis, while in finance, it predicts market trends and detects fraud. However, the integration of AI raises ethical considerations, such as job displacement and privacy concerns. \nOrganizations and policymakers must balance innovation with responsibility to ensure AI benefits society at large.\n\"\"\"\n\n# Prepend \"summarize: \" to the text\ninput_text = \"summarize: \" + text\n\n# Tokenize the input and move inputs to the same device as the model\ninputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n\n# Generate the summary\noutputs = model.generate(inputs, max_length=50, num_beams=2, early_stopping=True)\n\n# Decode and print the summary\nsummary = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(\"Summary:\", summary)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:34:29.059339Z","iopub.execute_input":"2024-10-30T06:34:29.059868Z","iopub.status.idle":"2024-10-30T06:34:30.043033Z","shell.execute_reply.started":"2024-10-30T06:34:29.059825Z","shell.execute_reply":"2024-10-30T06:34:30.042021Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Summary: AI-driven solutions provide valuable insights and streamline processes. In healthcare, AI aids in early disease detection through image analysis. In finance, AI predicts market trends and detects fraud. Organizations and policymakers must balance innovation\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the word count for the original text\noriginal_word_count = len(text.split())\n# Calculate the word count for the summarized text\nsummary_word_count = len(summary.split())\n# Display the results\nprint(\"Original Text Word Count:\", original_word_count)\nprint(\"Summary Word Count:\", summary_word_count)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:35:38.549968Z","iopub.execute_input":"2024-10-30T06:35:38.550736Z","iopub.status.idle":"2024-10-30T06:35:38.556237Z","shell.execute_reply.started":"2024-10-30T06:35:38.550696Z","shell.execute_reply":"2024-10-30T06:35:38.555370Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Original Text Word Count: 84\nSummary Word Count: 34\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# compare summaries before and after fine-tuning ","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# Load the tokenizer and pre-trained T5 model\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n\n# Load the pre-trained T5 model (before fine-tuning)\npretrained_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n\n# Load the fine-tuned T5 model (replace \"path/to/fine-tuned-t5\" with the path to your fine-tuned model)\nfine_tuned_model = T5ForConditionalGeneration.from_pretrained(\"./fine-tuned-t5\")\n\n# Check if a GPU is available and set the device accordingly\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Move both models to the appropriate device\npretrained_model.to(device)\nfine_tuned_model.to(device)\n\n# Sample text to summarize\ntext = \"\"\"\nArtificial intelligence (AI) has revolutionized various industries by automating complex tasks and analyzing vast amounts of data with precision. From healthcare to finance, AI-driven solutions provide valuable insights and streamline processes. \nFor instance, in healthcare, AI aids in early disease detection through image analysis, while in finance, it predicts market trends and detects fraud. However, the integration of AI raises ethical considerations, such as job displacement and privacy concerns. \nOrganizations and policymakers must balance innovation with responsibility to ensure AI benefits society at large.\n\"\"\"\n\n# Prepare the input text for the model\ninput_text = \"summarize: \" + text\ninputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n\n# Generate the summary using the pre-trained T5 model\nwith torch.no_grad():\n    pretrained_summary_ids = pretrained_model.generate(inputs, max_length=50, num_beams=2, early_stopping=True)\n    pretrained_summary = tokenizer.decode(pretrained_summary_ids[0], skip_special_tokens=True)\n\n# Generate the summary using the fine-tuned T5 model\nwith torch.no_grad():\n    fine_tuned_summary_ids = fine_tuned_model.generate(inputs, max_length=50, num_beams=2, early_stopping=True)\n    fine_tuned_summary = tokenizer.decode(fine_tuned_summary_ids[0], skip_special_tokens=True)\n\n# Print and compare the summaries\nprint(\"Original Text Word Count:\", len(text.split()))\nprint(\"\\nPre-trained Model Summary:\", pretrained_summary)\nprint(\"Pre-trained Summary Word Count:\", len(pretrained_summary.split()))\n\nprint(\"\\nFine-tuned Model Summary:\", fine_tuned_summary)\nprint(\"Fine-tuned Summary Word Count:\", len(fine_tuned_summary.split()))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T06:37:39.840078Z","iopub.execute_input":"2024-10-30T06:37:39.840482Z","iopub.status.idle":"2024-10-30T06:37:42.107853Z","shell.execute_reply.started":"2024-10-30T06:37:39.840440Z","shell.execute_reply":"2024-10-30T06:37:42.106826Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Original Text Word Count: 84\n\nPre-trained Model Summary: AI-driven solutions provide valuable insights and streamline processes. in healthcare, AI aids in early disease detection through image analysis. in finance, it predicts market trends and detects fraud.\nPre-trained Summary Word Count: 28\n\nFine-tuned Model Summary: AI-driven solutions provide valuable insights and streamline processes. In healthcare, AI aids in early disease detection through image analysis. In finance, AI predicts market trends and detects fraud. Organizations and policymakers must balance innovation\nFine-tuned Summary Word Count: 34\n","output_type":"stream"}]}]}